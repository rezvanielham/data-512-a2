{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1,2: Data Acquisition and Processing\n",
    "\n",
    "In this ste[ we are going to download data from following sources and save it as .csv for further processing:\n",
    "\n",
    "- Wikipedia articles data is downloaded from figshare. This project contains data on most English-language Wikipedia articles within the category \"Category:Politicians by nationality\" and subcategories, along with the code used to generate that data.\n",
    "- Population data is downloaded from Population Reference Bureau(PRB). This data is from year 2015 for 210 countries.\n",
    "\n",
    "In the next steps, we will get the article quality prediction by calling ORES api and merge article_quality with wikipedia and population data in a single dataframe. We will then write the dataframe in a csv file and save it to disk\n",
    "\n",
    "### Getting the Data and Appending ORES Prediction Values \n",
    "\n",
    "In this step we will be reading the csv files in and appending the ORES Prediction values to their corresponding dataframe rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page Data: Read from csv and append ORES info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Reading data from page_data.csv')\n",
    "\n",
    "data = []\n",
    "with open('page_data.csv', encoding='utf-8') as page_file:\n",
    "    reader = csv.reader(page_file)\n",
    "    next(reader)\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "url = 'https://ores.wikimedia.org/v3/scores/enwiki/?models=wp10&revids='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using the threadpooling will approximately decrease the execution time by 11 times.\n",
    "Without the pooling it will take close to 11 hours while using pooling we will have the results in less than 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_pool(row):\n",
    "    # create url for API request\n",
    "    tmp_url = url + row[2]\n",
    "    try:\n",
    "        # get request\n",
    "        result = requests.get(url=tmp_url).json()['enwiki']['scores']\n",
    "        # get prediction name\n",
    "        prediction = result[row[2]]['wp10']['score']['prediction']\n",
    "        return row + [prediction]\n",
    "    except:\n",
    "        return row + [None]\n",
    "print('Collecting data using API (please wait about 1 hour...)')\n",
    "\n",
    "pool = ThreadPool(28)\n",
    "page_data_with_prediction = pool.map(for_pool, data)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Data: Read from csv and process\n",
    "\n",
    "Once data is loaded, the population data needs some processing before it's ready to use. The first two rows and 'Foonotes' column needs to be trimmed. The format for population data needs to be changed to number so that it can be used for percentage calculation in later steps. Below section applies the steps mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First, create a dictionary of key: value pairs: key - country name, value - population.\n",
    "population_data = {}\n",
    "with open('Population Mid-2015.csv', encoding='utf-8') as population_file:\n",
    "    reader = csv.reader(population_file)\n",
    "    next(reader)\n",
    "    next(reader)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        try:\n",
    "            population_data[row[0]] = int(row[4].replace(',',''))\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final dataset\n",
    "For each row in page_data_with_prediction, if score exists and if the population_data has country population, add population in the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_dataset = []\n",
    "for row in page_data_with_prediction:\n",
    "    if row[3] != None:\n",
    "        try:\n",
    "            population = population_data[row[1]]\n",
    "            final_dataset.append(row + [population])\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writing the final data set to the disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldname = ['article_name', 'country', 'revision_id', 'article_quality', 'population']\n",
    "with open('final_dataset.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(fieldname)\n",
    "    writer.writerows(final_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Analysis\n",
    "\n",
    "In this step we are going to calculate the percentage of articles-per-population for each country and\n",
    "the percentage of high-quality articles(where prediction is either 'FA' or 'GA') for each country.\n",
    "Based on the results, we will produce four tables that show:\n",
    "1. 10 highest-ranked countries in terms of number of politician articles as a proportion of country population\n",
    "2. 10 lowest-ranked countries in terms of number of politician articles as a proportion of country population\n",
    "3. 10 highest-ranked countries in terms of number of GA and FA-quality articles as a proportion of all articles about politicians from that country\n",
    "4. 10 lowest-ranked countries in terms of number of GA and FA-quality articles as a proportion of all articles about politicians from that country\n",
    "\n",
    "\n",
    "The code below performs the percentage calculations for articles-per-population for each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data in pandas dataframe\n",
    "final_dataset = pd.read_csv('final_dataset.csv')\n",
    "\n",
    "# find all unique countries in dataframe\n",
    "countries = final_dataset['country'].unique()\n",
    "\n",
    "articles_per_population = []\n",
    "# for each country find articles_per_population\n",
    "for country in countries:\n",
    "    tmp_dataset = final_dataset[final_dataset['country'] == country]\n",
    "    articles = len(tmp_dataset)\n",
    "    population = tmp_dataset['population'].iloc[0]\n",
    "    articles_per_population.append([country, articles/population*100])\n",
    "\n",
    "articles_per_population = list(zip(*articles_per_population))    \n",
    "articles_per_population = pd.DataFrame({'country': articles_per_population[0],\n",
    "                                        'articles_per_population': articles_per_population[1]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 1: 10 highest-ranked countries in terms of number of politician articles as a proportion of country population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles_per_population.sort_values('articles_per_population').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 2: 10 lowest-ranked countries in terms of number of politician articles as a proportion of country population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles_per_population.sort_values('articles_per_population', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below performs the percentage calculations of high-quality articles(where prediction is either 'FA' or 'GA') for each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_quality_articles = []\n",
    "# for each country find high_quality_articles \n",
    "for country in countries:\n",
    "    tmp_dataset = final_dataset[final_dataset['country'] == country]\n",
    "    row_index = ((tmp_dataset.article_quality == 'GA') | (tmp_dataset.article_quality == 'FA'))\n",
    "    tmp_high_quality = tmp_dataset[row_index]\n",
    "    high_quality_articles.append([country, len(tmp_high_quality)/len(tmp_dataset)*100])\n",
    "    \n",
    "high_quality_articles = list(zip(*high_quality_articles))    \n",
    "high_quality_articles = pd.DataFrame({'country': high_quality_articles[0],\n",
    "                                        'high_quality_articles': high_quality_articles[1]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 3: 10 highest-ranked countries in terms of number of GA and FA-quality articles as a proportion of all articles about politicians from that country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_quality_articles.sort_values('high_quality_articles', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 4: 10 lowest-ranked countries in terms of number of GA and FA-quality articles as a proportion of all articles about politicians from that country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_quality_articles.sort_values('high_quality_articles').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step4: Reflection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
